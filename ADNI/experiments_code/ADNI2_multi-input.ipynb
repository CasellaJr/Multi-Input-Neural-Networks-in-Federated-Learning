{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64568f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ACSConv\n",
      "  Downloading ACSConv-0.1.1.tar.gz (15 kB)\n",
      "Collecting fire\n",
      "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
      "\u001b[K     |████████████████████████████████| 88 kB 666 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/user1/anaconda3/lib/python3.8/site-packages (from ACSConv) (1.20.1)\n",
      "Requirement already satisfied: matplotlib in /home/user1/.local/lib/python3.8/site-packages (from ACSConv) (3.5.1)\n",
      "Requirement already satisfied: pandas in /home/user1/anaconda3/lib/python3.8/site-packages (from ACSConv) (1.2.4)\n",
      "Requirement already satisfied: tqdm in /home/user1/anaconda3/lib/python3.8/site-packages (from ACSConv) (4.59.0)\n",
      "Requirement already satisfied: scikit-image in /home/user1/anaconda3/lib/python3.8/site-packages (from ACSConv) (0.18.1)\n",
      "Requirement already satisfied: scikit-learn in /home/user1/anaconda3/lib/python3.8/site-packages (from ACSConv) (0.24.1)\n",
      "Requirement already satisfied: scipy in /home/user1/anaconda3/lib/python3.8/site-packages (from ACSConv) (1.6.2)\n",
      "Collecting tensorboardx\n",
      "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[K     |████████████████████████████████| 125 kB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch in /home/user1/anaconda3/lib/python3.8/site-packages (from ACSConv) (1.13.1)\n",
      "Requirement already satisfied: torchvision in /home/user1/anaconda3/lib/python3.8/site-packages (from ACSConv) (0.14.1)\n",
      "Requirement already satisfied: six in /home/user1/anaconda3/lib/python3.8/site-packages (from fire->ACSConv) (1.15.0)\n",
      "Collecting termcolor\n",
      "  Downloading termcolor-2.1.1-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/user1/.local/lib/python3.8/site-packages (from matplotlib->ACSConv) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/user1/.local/lib/python3.8/site-packages (from matplotlib->ACSConv) (4.28.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/user1/anaconda3/lib/python3.8/site-packages (from matplotlib->ACSConv) (20.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/user1/.local/lib/python3.8/site-packages (from matplotlib->ACSConv) (8.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/user1/anaconda3/lib/python3.8/site-packages (from matplotlib->ACSConv) (2.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/user1/anaconda3/lib/python3.8/site-packages (from matplotlib->ACSConv) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/user1/.local/lib/python3.8/site-packages (from matplotlib->ACSConv) (1.3.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/user1/anaconda3/lib/python3.8/site-packages (from pandas->ACSConv) (2021.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /home/user1/anaconda3/lib/python3.8/site-packages (from scikit-image->ACSConv) (2.5)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /home/user1/anaconda3/lib/python3.8/site-packages (from scikit-image->ACSConv) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/user1/anaconda3/lib/python3.8/site-packages (from scikit-image->ACSConv) (2020.10.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/user1/anaconda3/lib/python3.8/site-packages (from scikit-image->ACSConv) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/user1/anaconda3/lib/python3.8/site-packages (from networkx>=2.0->scikit-image->ACSConv) (5.0.6)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/user1/anaconda3/lib/python3.8/site-packages (from scikit-learn->ACSConv) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/user1/anaconda3/lib/python3.8/site-packages (from scikit-learn->ACSConv) (1.0.1)\n",
      "Collecting protobuf<=3.20.1,>=3.8.0\n",
      "  Downloading protobuf-3.20.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 5.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing_extensions in /home/user1/anaconda3/lib/python3.8/site-packages (from torch->ACSConv) (3.7.4.3)\n",
      "Requirement already satisfied: requests in /home/user1/anaconda3/lib/python3.8/site-packages (from torchvision->ACSConv) (2.25.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/user1/anaconda3/lib/python3.8/site-packages (from requests->torchvision->ACSConv) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/user1/anaconda3/lib/python3.8/site-packages (from requests->torchvision->ACSConv) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/user1/anaconda3/lib/python3.8/site-packages (from requests->torchvision->ACSConv) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user1/anaconda3/lib/python3.8/site-packages (from requests->torchvision->ACSConv) (2020.12.5)\n",
      "Building wheels for collected packages: ACSConv, fire\n",
      "  Building wheel for ACSConv (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ACSConv: filename=ACSConv-0.1.1-py3-none-any.whl size=24202 sha256=3be30739b7fce33b82ab0e8a4b8bd54210b746bc9d57bb41efa2e36da44d526f\n",
      "  Stored in directory: /home/user1/.cache/pip/wheels/46/0a/29/16aa677f167ed02fb8eb81ffef716f426304fe749db6d05135\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116934 sha256=7cef1badddfe829769318035c9d086595f924ffe6e57a071aa42e97a9c3dadaf\n",
      "  Stored in directory: /home/user1/.cache/pip/wheels/5b/eb/43/7295e71293b218ddfd627f935229bf54af9018add7fbb5aac6\n",
      "Successfully built ACSConv fire\n",
      "Installing collected packages: termcolor, protobuf, tensorboardx, fire, ACSConv\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-datasets 4.4.0 requires importlib-resources; python_version < \"3.9\", which is not installed.\u001b[0m\n",
      "Successfully installed ACSConv-0.1.1 fire-0.5.0 protobuf-3.20.1 tensorboardx-2.5.1 termcolor-2.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install ACSConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcca7d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torch\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torchvision import utils, transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.model_selection import KFold\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import intel_extension_for_pytorch as ipex\n",
    "\n",
    "myseed = 1\n",
    "torch.manual_seed(myseed)\n",
    "np.random.seed(myseed)\n",
    "\n",
    "num_classes=2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6e4f354",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd3e8fa",
   "metadata": {},
   "source": [
    "### 1) Data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa933ad9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!ls a2/ADNI2_ALL_T1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b66714f",
   "metadata": {},
   "source": [
    "#### Retrieve img filenames and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b054889c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final data has 260\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PTID</th>\n",
       "      <th>IMG_PATH</th>\n",
       "      <th>SRC_PATH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>094_S_4459</td>\n",
       "      <td>a2/ADNI2_ALL_T1/094_S_4459.nii.gz</td>\n",
       "      <td>a2/T1/094_S_4459/Accelerated_SAG_IR-SPGR/fsl_a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>137_S_4211</td>\n",
       "      <td>a2/ADNI2_ALL_T1/137_S_4211.nii.gz</td>\n",
       "      <td>a2/T1/137_S_4211/MPRAGE/fsl_anat.anat/T1_to_MN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>052_S_4959</td>\n",
       "      <td>a2/ADNI2_ALL_T1/052_S_4959.nii.gz</td>\n",
       "      <td>a2/T1/052_S_4959/Accelerated_Sag_IR-SPGR/fsl_a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>022_S_4196</td>\n",
       "      <td>a2/ADNI2_ALL_T1/022_S_4196.nii.gz</td>\n",
       "      <td>a2/T1/022_S_4196/MPRAGE/fsl_anat.anat/T1_to_MN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>029_S_4290</td>\n",
       "      <td>a2/ADNI2_ALL_T1/029_S_4290.nii.gz</td>\n",
       "      <td>a2/T1/029_S_4290/Accelerated_SAG_IR-FSPGR/fsl_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PTID                           IMG_PATH  \\\n",
       "0  094_S_4459  a2/ADNI2_ALL_T1/094_S_4459.nii.gz   \n",
       "1  137_S_4211  a2/ADNI2_ALL_T1/137_S_4211.nii.gz   \n",
       "2  052_S_4959  a2/ADNI2_ALL_T1/052_S_4959.nii.gz   \n",
       "3  022_S_4196  a2/ADNI2_ALL_T1/022_S_4196.nii.gz   \n",
       "4  029_S_4290  a2/ADNI2_ALL_T1/029_S_4290.nii.gz   \n",
       "\n",
       "                                            SRC_PATH  \n",
       "0  a2/T1/094_S_4459/Accelerated_SAG_IR-SPGR/fsl_a...  \n",
       "1  a2/T1/137_S_4211/MPRAGE/fsl_anat.anat/T1_to_MN...  \n",
       "2  a2/T1/052_S_4959/Accelerated_Sag_IR-SPGR/fsl_a...  \n",
       "3  a2/T1/022_S_4196/MPRAGE/fsl_anat.anat/T1_to_MN...  \n",
       "4  a2/T1/029_S_4290/Accelerated_SAG_IR-FSPGR/fsl_...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specifying the zip file name\n",
    "adni_num = \"2\"\n",
    "data_path = f\"a{adni_num}\"\n",
    "#img_path = \"a2/ADNI2_ALL_T1/\"\n",
    "\n",
    "img_df_filename=f\"adni{adni_num}_paths.pkl\"\n",
    "filename=os.path.join(data_path, img_df_filename)\n",
    "img_df=pd.read_pickle(filename)  \n",
    "\n",
    "print(f\"Final data has {len(img_df)}\")\n",
    "img_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1ea0ea",
   "metadata": {},
   "source": [
    "#### Retrieve ADNI table, with normalized values (ADNI_ready.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0cb9b90b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL adni has 961 entries\n",
      "Class distribution is organized as follow:\n",
      "\n",
      " 0    583\n",
      "1    378\n",
      "Name: labels, dtype: int64\n",
      "Adni2 has 288 entries\n",
      "Class distribution is organized as follow:\n",
      "Final:\n",
      " 0    145\n",
      "1    143\n",
      "Name: labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_path = \"ADNI_csv/\"\n",
    "filename = \"ADNI_ready.csv\"\n",
    "\n",
    "adni_tabular = pd.read_csv(os.path.join(data_path, filename))\n",
    "adni_tabular.head()\n",
    "\n",
    "\n",
    "# Print \n",
    "print(f\"ALL adni has {len(adni_tabular)} entries\")\n",
    "print(f\"Class distribution is organized as follow:\")\n",
    "print(f\"\\n {adni_tabular['labels'].value_counts()}\")\n",
    "\n",
    "adni_tabular=adni_tabular[adni_tabular['SRC']==f\"ADNI{adni_num}\"]\n",
    "\n",
    "print(f\"Adni{adni_num} has {len(adni_tabular)} entries\")\n",
    "print(f\"Class distribution is organized as follow:\")\n",
    "print(f\"Final:\\n {adni_tabular['labels'].value_counts()}\")\n",
    "\n",
    "\n",
    "## Check for duplicated rows\n",
    "dup = adni_tabular[adni_tabular.duplicated()]\n",
    "if not dup.empty:\n",
    "    print(f\"WARNING: Dataframe contains duplicated rows!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b5e8af",
   "metadata": {},
   "source": [
    "#### Merge the images and tabular dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba00f6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only ADNI2 subjects\n",
    "adni = pd.merge( left=img_df, right=adni_tabular, how=\"inner\", on=\"PTID\", \n",
    "                      suffixes=(\"_x\", \"_y\"),copy=False, indicator=False, validate=\"one_to_one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0be0ce85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution is organized as follow:\n",
      "Final:\n",
      " 0    145\n",
      "1     88\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PTID</th>\n",
       "      <th>IMG_PATH</th>\n",
       "      <th>SRC_PATH</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>labels</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PTGENDER</th>\n",
       "      <th>ADAS11</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>FAQ</th>\n",
       "      <th>CDRSB</th>\n",
       "      <th>APOE4</th>\n",
       "      <th>RAVLT_immediate</th>\n",
       "      <th>RAVLT_learning</th>\n",
       "      <th>RAVLT_forgetting</th>\n",
       "      <th>SRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137_S_4211</td>\n",
       "      <td>a2/ADNI2_ALL_T1/137_S_4211.nii.gz</td>\n",
       "      <td>a2/T1/137_S_4211/MPRAGE/fsl_anat.anat/T1_to_MN...</td>\n",
       "      <td>277</td>\n",
       "      <td>1</td>\n",
       "      <td>1.010212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.049563</td>\n",
       "      <td>-1.411360</td>\n",
       "      <td>-0.317334</td>\n",
       "      <td>1.313287</td>\n",
       "      <td>-0.793893</td>\n",
       "      <td>-1.144230</td>\n",
       "      <td>-0.772101</td>\n",
       "      <td>-1.218351</td>\n",
       "      <td>ADNI2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>052_S_4959</td>\n",
       "      <td>a2/ADNI2_ALL_T1/052_S_4959.nii.gz</td>\n",
       "      <td>a2/T1/052_S_4959/Accelerated_Sag_IR-SPGR/fsl_a...</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>0.509276</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.550948</td>\n",
       "      <td>-0.505942</td>\n",
       "      <td>1.973669</td>\n",
       "      <td>1.313287</td>\n",
       "      <td>0.722869</td>\n",
       "      <td>-0.720327</td>\n",
       "      <td>-1.118016</td>\n",
       "      <td>0.396038</td>\n",
       "      <td>ADNI2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>022_S_4196</td>\n",
       "      <td>a2/ADNI2_ALL_T1/022_S_4196.nii.gz</td>\n",
       "      <td>a2/T1/022_S_4196/MPRAGE/fsl_anat.anat/T1_to_MN...</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0.641877</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.250585</td>\n",
       "      <td>1.003090</td>\n",
       "      <td>-0.699168</td>\n",
       "      <td>-0.756357</td>\n",
       "      <td>-0.793893</td>\n",
       "      <td>0.904636</td>\n",
       "      <td>1.303392</td>\n",
       "      <td>-0.814754</td>\n",
       "      <td>ADNI2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>029_S_4290</td>\n",
       "      <td>a2/ADNI2_ALL_T1/029_S_4290.nii.gz</td>\n",
       "      <td>a2/T1/029_S_4290/Accelerated_SAG_IR-FSPGR/fsl_...</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.080060</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.310743</td>\n",
       "      <td>0.701283</td>\n",
       "      <td>-0.699168</td>\n",
       "      <td>-0.756357</td>\n",
       "      <td>0.722869</td>\n",
       "      <td>0.198130</td>\n",
       "      <td>-0.080270</td>\n",
       "      <td>0.396038</td>\n",
       "      <td>ADNI2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>127_S_4940</td>\n",
       "      <td>a2/ADNI2_ALL_T1/127_S_4940.nii.gz</td>\n",
       "      <td>a2/T1/029_S_4290/Accelerated_SAG_IR-FSPGR/fsl_...</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>2.247818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.112276</td>\n",
       "      <td>-0.807748</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.278465</td>\n",
       "      <td>-0.793893</td>\n",
       "      <td>-1.497483</td>\n",
       "      <td>-0.426185</td>\n",
       "      <td>-0.007560</td>\n",
       "      <td>ADNI2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PTID                           IMG_PATH  \\\n",
       "0  137_S_4211  a2/ADNI2_ALL_T1/137_S_4211.nii.gz   \n",
       "1  052_S_4959  a2/ADNI2_ALL_T1/052_S_4959.nii.gz   \n",
       "2  022_S_4196  a2/ADNI2_ALL_T1/022_S_4196.nii.gz   \n",
       "3  029_S_4290  a2/ADNI2_ALL_T1/029_S_4290.nii.gz   \n",
       "4  127_S_4940  a2/ADNI2_ALL_T1/127_S_4940.nii.gz   \n",
       "\n",
       "                                            SRC_PATH  Unnamed: 0  labels  \\\n",
       "0  a2/T1/137_S_4211/MPRAGE/fsl_anat.anat/T1_to_MN...         277       1   \n",
       "1  a2/T1/052_S_4959/Accelerated_Sag_IR-SPGR/fsl_a...         147       1   \n",
       "2  a2/T1/022_S_4196/MPRAGE/fsl_anat.anat/T1_to_MN...          81       0   \n",
       "3  a2/T1/029_S_4290/Accelerated_SAG_IR-FSPGR/fsl_...          99       0   \n",
       "4  a2/T1/029_S_4290/Accelerated_SAG_IR-FSPGR/fsl_...         230       1   \n",
       "\n",
       "        AGE  PTGENDER    ADAS11      MMSE       FAQ     CDRSB     APOE4  \\\n",
       "0  1.010212       0.0 -0.049563 -1.411360 -0.317334  1.313287 -0.793893   \n",
       "1  0.509276       1.0  0.550948 -0.505942  1.973669  1.313287  0.722869   \n",
       "2  0.641877       1.0 -1.250585  1.003090 -0.699168 -0.756357 -0.793893   \n",
       "3 -0.080060       1.0  0.310743  0.701283 -0.699168 -0.756357  0.722869   \n",
       "4  2.247818       1.0  2.112276 -0.807748  0.064500  0.278465 -0.793893   \n",
       "\n",
       "   RAVLT_immediate  RAVLT_learning  RAVLT_forgetting    SRC  \n",
       "0        -1.144230       -0.772101         -1.218351  ADNI2  \n",
       "1        -0.720327       -1.118016          0.396038  ADNI2  \n",
       "2         0.904636        1.303392         -0.814754  ADNI2  \n",
       "3         0.198130       -0.080270          0.396038  ADNI2  \n",
       "4        -1.497483       -0.426185         -0.007560  ADNI2  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Class distribution is organized as follow:\")\n",
    "print(f\"Final:\\n {adni['labels'].value_counts()}\")\n",
    "adni.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "20d7f4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['109_S_4378', '003_S_4839', '136_S_4726', '013_S_4731', '036_S_4740', '035_S_4783', '082_S_5029', '127_S_4749', '041_S_4083', '098_S_4002', '032_S_4304', '094_S_4460', '057_S_4110', '037_S_4001', '123_S_4362', '036_S_5149', '068_S_5206', '116_S_4537', '094_S_4459', '099_S_4124', '003_S_4840', '136_S_4727', '012_S_4642', '100_S_5246', '041_S_4509', '068_S_5146', '100_S_4511']\n",
      "109_S_4378 Missing tabular\n",
      "003_S_4839 Missing tabular\n",
      "136_S_4726 Missing tabular\n",
      "013_S_4731 Missing tabular\n",
      "036_S_4740 Missing tabular\n",
      "035_S_4783 Missing tabular\n",
      "082_S_5029 Missing tabular\n",
      "127_S_4749 Missing tabular\n",
      "041_S_4083 Missing tabular\n",
      "098_S_4002 Missing tabular\n",
      "032_S_4304 Missing tabular\n",
      "094_S_4460 Missing tabular\n",
      "057_S_4110 Missing tabular\n",
      "037_S_4001 Missing tabular\n",
      "123_S_4362 Missing tabular\n",
      "036_S_5149 Missing tabular\n",
      "068_S_5206 Missing tabular\n",
      "116_S_4537 Missing tabular\n",
      "094_S_4459 Missing tabular\n",
      "099_S_4124 Missing tabular\n",
      "003_S_4840 Missing tabular\n",
      "136_S_4727 Missing tabular\n",
      "012_S_4642 Missing tabular\n",
      "100_S_5246 Missing tabular\n",
      "041_S_4509 Missing tabular\n",
      "068_S_5146 Missing tabular\n",
      "100_S_4511 Missing tabular\n"
     ]
    }
   ],
   "source": [
    "## Check for subjects with missing images/tabular\n",
    "\n",
    "images_pk = img_df['PTID'].tolist()\n",
    "adni_pk = adni_tabular['PTID'].tolist()\n",
    "\n",
    "intersection = list(set(images_pk) - set(adni_pk))\n",
    "print(intersection)\n",
    "for ptid in intersection:\n",
    "    \n",
    "    if ptid in images_pk:\n",
    "        print(f\"{ptid} Missing tabular\")\n",
    "\n",
    "    elif ptid in adni_pk:\n",
    "        print(f\"{ptid} Missing Image\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c203d2ff",
   "metadata": {},
   "source": [
    "### 2) Dataset creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "713ead29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgDataset(Dataset):\n",
    "    \"\"\"Tabular and Image dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, adni_df):\n",
    "        self.adni = adni_df\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.adni)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        line = self.adni.iloc[idx, 0:]\n",
    "        # Get Label\n",
    "        y = line['labels']\n",
    "\n",
    "        # Get tabular\n",
    "        tabular = line[['AGE','PTGENDER','ADAS11', 'MMSE', 'FAQ', \\\n",
    "                   'RAVLT_immediate', 'RAVLT_learning', 'RAVLT_forgetting', \\\n",
    "                   'CDRSB', 'APOE4']]\n",
    "        tabular = torch.DoubleTensor(tabular)\n",
    "        \n",
    "        # Get image\n",
    "        image = nib.load(line['IMG_PATH'])\n",
    "        image = image.get_fdata() \n",
    "        #image = image[..., :3]\n",
    "        image = transforms.functional.to_tensor(image)\n",
    "        image = image.unsqueeze(dim=0)\n",
    "        \n",
    "        return image, tabular, y\n",
    "\n",
    "img_data = ImgDataset(adni_df=adni)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d309420d",
   "metadata": {},
   "source": [
    "### Detach test set and use remaining data for train-val k-fold split (further down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ce539489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        PTID  IMG_PATH  SRC_PATH  Unnamed: 0  AGE  PTGENDER  ADAS11  MMSE  \\\n",
      "labels                                                                      \n",
      "0        130       130       130         130  130       130     130   130   \n",
      "1         79        79        79          79   79        79      79    79   \n",
      "\n",
      "        FAQ  CDRSB  APOE4  RAVLT_immediate  RAVLT_learning  RAVLT_forgetting  \\\n",
      "labels                                                                         \n",
      "0       130    130    130              130             130               130   \n",
      "1        79     79     79               79              79                79   \n",
      "\n",
      "        SRC  \n",
      "labels       \n",
      "0       130  \n",
      "1        79  \n",
      "        PTID  IMG_PATH  SRC_PATH  Unnamed: 0  AGE  PTGENDER  ADAS11  MMSE  \\\n",
      "labels                                                                      \n",
      "0         15        15        15          15   15        15      15    15   \n",
      "1          9         9         9           9    9         9       9     9   \n",
      "\n",
      "        FAQ  CDRSB  APOE4  RAVLT_immediate  RAVLT_learning  RAVLT_forgetting  \\\n",
      "labels                                                                         \n",
      "0        15     15     15               15              15                15   \n",
      "1         9      9      9                9               9                 9   \n",
      "\n",
      "        SRC  \n",
      "labels       \n",
      "0        15  \n",
      "1         9  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "labels = adni['labels'].tolist()\n",
    "# Split data into train+val and test set indexes\n",
    "tv_idx, test_idx = train_test_split(np.arange(len(labels)), test_size=0.1,shuffle=True,stratify=labels)\n",
    "\n",
    "# Create train+val dataframe and show class balance\n",
    "adni_tv = adni.iloc[tv_idx]\n",
    "print(adni_tv.groupby([\"labels\"]).count())\n",
    "tv_data = ImgDataset(adni_df=adni_tv)\n",
    "\n",
    "# Create test dataframe and show class balance\n",
    "adni_test = adni.iloc[test_idx]\n",
    "print(adni_test.groupby([\"labels\"]).count())\n",
    "test_data = ImgDataset(adni_df=adni_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f70de888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 91, 91, 109]), tabular = tensor([ 1.2165,  0.0000, -0.4099,  1.0031, -0.6992, -0.0138,  0.6116, -0.4112,\n",
      "        -0.7564,  0.7229], dtype=torch.float64), label = 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 14\n",
    "print(f\"{test_data[i][0].size()}, tabular = {test_data[i][1]}, label = {test_data[i][2]}\")\n",
    "\n",
    "len(test_data[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bacb7a",
   "metadata": {},
   "source": [
    "### 3. Model: img+tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "80aeae43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv3d(1, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
      "  (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (maxpool): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
      "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
      "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
      "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (ln1): Linear(in_features=10, out_features=50, bias=True)\n",
      "  (ln2): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (ln3): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (ln4): Linear(in_features=20, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def get_inplanes():\n",
    "    return [64, 128, 256, 512]\n",
    "\n",
    "\n",
    "def conv3x3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv3d(in_planes,\n",
    "                     out_planes,\n",
    "                     kernel_size=3,\n",
    "                     stride=stride,\n",
    "                     padding=1,\n",
    "                     bias=False)\n",
    "\n",
    "\n",
    "def conv1x1x1(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv3d(in_planes,\n",
    "                     out_planes,\n",
    "                     kernel_size=1,\n",
    "                     stride=stride,\n",
    "                     bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = conv3x3x3(in_planes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = conv1x1x1(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.conv2 = conv3x3x3(planes, planes, stride)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.conv3 = conv1x1x1(planes, planes * self.expansion)\n",
    "        self.bn3 = nn.BatchNorm3d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, block_inplanes, \\\n",
    "                 n_input_channels=3, conv1_t_size=7, \\\n",
    "                 conv1_t_stride=1, no_max_pool=False, \\\n",
    "                 shortcut_type='B', widen_factor=1.0, \\\n",
    "                 n_classes=400, img_contribution=10, \\\n",
    "                 tabular_val=10, tabular_contribution=10):\n",
    "        super().__init__()\n",
    "\n",
    "        block_inplanes = [int(x * widen_factor) for x in block_inplanes]\n",
    "\n",
    "        self.in_planes = block_inplanes[0]\n",
    "        self.no_max_pool = no_max_pool\n",
    "\n",
    "        self.conv1 = nn.Conv3d(n_input_channels,\n",
    "                               self.in_planes,\n",
    "                               kernel_size=(conv1_t_size, 7, 7),\n",
    "                               stride=(conv1_t_stride, 2, 2),\n",
    "                               padding=(conv1_t_size // 2, 3, 3),\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(self.in_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, block_inplanes[0], layers[0],\n",
    "                                       shortcut_type)\n",
    "        self.layer2 = self._make_layer(block,\n",
    "                                       block_inplanes[1],\n",
    "                                       layers[1],\n",
    "                                       shortcut_type,\n",
    "                                       stride=2)\n",
    "        self.layer3 = self._make_layer(block,\n",
    "                                       block_inplanes[2],\n",
    "                                       layers[2],\n",
    "                                       shortcut_type,\n",
    "                                       stride=2)\n",
    "        self.layer4 = self._make_layer(block,\n",
    "                                       block_inplanes[3],\n",
    "                                       layers[3],\n",
    "                                       shortcut_type,\n",
    "                                       stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.fc = nn.Linear(block_inplanes[3] * block.expansion, img_contribution)\n",
    "        \n",
    "        #qui ho cambiato da num_classes a 10, per far cat con testo\n",
    "        #TESTO\n",
    "        self.relu = nn.ReLU()\n",
    "        self.ln1 = nn.Linear(tabular_val, 50) #23 sono le colonne in input\n",
    "        self.ln2 = nn.Linear(50, 50)\n",
    "        self.ln3 = nn.Linear(50, tabular_contribution)\n",
    "        self.ln4 = nn.Linear(tabular_contribution+img_contribution, n_classes) #20 perchè 10 derivano da img e 10 da tab\n",
    "        \n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight,\n",
    "                                        mode='fan_out',\n",
    "                                        nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _downsample_basic_block(self, x, planes, stride):\n",
    "        out = F.avg_pool3d(x, kernel_size=1, stride=stride)\n",
    "        zero_pads = torch.zeros(out.size(0), planes - out.size(1), out.size(2),\n",
    "                                out.size(3), out.size(4))\n",
    "        if isinstance(out.data, torch.FloatTensor):\n",
    "            zero_pads = zero_pads\n",
    "\n",
    "        out = torch.cat([out.data, zero_pads], dim=1)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, shortcut_type, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_planes != planes * block.expansion:\n",
    "            if shortcut_type == 'A':\n",
    "                downsample = partial(self._downsample_basic_block,\n",
    "                                     planes=planes * block.expansion,\n",
    "                                     stride=stride)\n",
    "            else:\n",
    "                downsample = nn.Sequential(\n",
    "                    conv1x1x1(self.in_planes, planes * block.expansion, stride),\n",
    "                    nn.BatchNorm3d(planes * block.expansion))\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(in_planes=self.in_planes,\n",
    "                  planes=planes,\n",
    "                  stride=stride,\n",
    "                  downsample=downsample))\n",
    "        self.in_planes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, tab):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        if not self.no_max_pool:\n",
    "            x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        tab = self.ln1(tab)\n",
    "        tab = self.relu(tab)\n",
    "        tab = self.ln2(tab)\n",
    "        tab = self.relu(tab)\n",
    "        tab = self.ln3(tab)\n",
    "        tab = self.relu(tab)\n",
    "        \n",
    "        x = torch.cat((x, tab), dim=1)\n",
    "        x= self.relu(x)\n",
    "        \n",
    "        x = self.ln4(x)        \n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def ResNet18(in_channels, num_classes):\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], in_channels=in_channels, num_classes=num_classes)\n",
    "\n",
    "\n",
    "def generate_model(model_depth, **kwargs):\n",
    "    assert model_depth in [10, 18, 34, 50, 101, 152, 200]\n",
    "\n",
    "    if model_depth == 10:\n",
    "        model = ResNet(BasicBlock, [1, 1, 1, 1], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 18:\n",
    "        model = ResNet(BasicBlock, [2, 2, 2, 2], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 34:\n",
    "        model = ResNet(BasicBlock, [3, 4, 6, 3], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 50:\n",
    "        model = ResNet(Bottleneck, [3, 4, 6, 3], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 101:\n",
    "        model = ResNet(Bottleneck, [3, 4, 23, 3], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 152:\n",
    "        model = ResNet(Bottleneck, [3, 8, 36, 3], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 200:\n",
    "        model = ResNet(Bottleneck, [3, 24, 36, 3], get_inplanes(), **kwargs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = generate_model(18, n_input_channels=1, widen_factor=1.0, \n",
    "                       n_classes=1, img_contribution=10, tabular_val=len(test_data[i][1]), tabular_contribution=10)\n",
    "model = model.double()\n",
    "print(model)\n",
    "#model = ResNet18(in_channels=91, num_classes=2)\n",
    "#model = Net(in_channels=n_channels, num_classes=n_classes)\n",
    "#model = model_to_syncbn(Conv3dConverter(model, i3d_repeat_axis=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25cad353",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_x, label_x = tv_set[0]\n",
    "#img_x.shape\n",
    "\n",
    "#img_x = img_x.unsqueeze(dim=0)\n",
    "#img_x = img_x.unsqueeze(dim=0)\n",
    "#output = model(img_x)\n",
    "#output.shape\n",
    "\n",
    "#output = model(img_x)\n",
    "#output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d4f2bb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, loaders, optimizer, criterion, epochs=500, dev=dev, save_param = False, model_name=\"adni_multi_input\"):\n",
    "    torch.manual_seed(myseed)\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        net = net.to(dev)\n",
    "        #print(net)\n",
    "        # Initialize history\n",
    "        history_loss = {\"train\": [], \"val\": [], \"test\": []}\n",
    "        history_accuracy = {\"train\": [], \"val\": [], \"test\": []}\n",
    "        # Store the best val accuracy\n",
    "        best_val_accuracy = 0\n",
    "\n",
    "        # Process each epoch\n",
    "        for epoch in range(epochs):\n",
    "            # Initialize epoch variables\n",
    "            sum_loss = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
    "            sum_accuracy = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
    "            # Process each split\n",
    "            for split in [\"train\", \"val\", \"test\"]:\n",
    "                if split == \"train\":\n",
    "                    net.train()\n",
    "                else:\n",
    "                    net.eval()\n",
    "                # Process each batch\n",
    "                for (image, tabular, labels) in loaders[split]:\n",
    "                    # Move to CUDA\n",
    "                    images = image.to(dev)\n",
    "                    tabular = tabular.to(dev)\n",
    "                    labels = labels.to(dev)\n",
    "                    # Reset gradients\n",
    "                    optimizer.zero_grad()\n",
    "                    # Compute output\n",
    "                    pred = net(image, tabular)\n",
    "                    #pred = pred.squeeze(dim=1) # Output shape is [Batch size, 1], but we want [Batch size]\n",
    "                    labels = labels.unsqueeze(1)\n",
    "                    labels = labels.float()\n",
    "                    loss = criterion(pred, labels)\n",
    "                    # Update loss\n",
    "                    sum_loss[split] += loss.item()\n",
    "                    # Check parameter update\n",
    "                    if split == \"train\":\n",
    "                        # Compute gradients\n",
    "                        loss.backward()\n",
    "                        # Optimize\n",
    "                        optimizer.step()\n",
    "                    # Compute accuracy\n",
    "                    #pred_labels = pred.argmax(1) + 1\n",
    "                    pred_labels = (pred >= 0).long() # Binarize predictions to 0 and 1\n",
    "                    batch_accuracy = (pred_labels == labels).sum().item()/image.size(0)\n",
    "                    # Update accuracy\n",
    "                    sum_accuracy[split] += batch_accuracy\n",
    "                scheduler.step()\n",
    "            # Compute epoch loss/accuracy\n",
    "            epoch_loss = {split: sum_loss[split]/len(loaders[split]) for split in [\"train\", \"val\", \"test\"]}\n",
    "            epoch_accuracy = {split: sum_accuracy[split]/len(loaders[split]) for split in [\"train\", \"val\", \"test\"]}\n",
    "\n",
    "            # Store params at the best validation accuracy\n",
    "            if save_param and epoch_accuracy[\"val\"] > best_val_accuracy:\n",
    "                #torch.save(net.state_dict(), f\"{net.__class__.__name__}_best_val.pth\")\n",
    "                torch.save(net.state_dict(), f\"{model_name}_best_val.pth\")\n",
    "                best_val_accuracy = epoch_accuracy[\"val\"]\n",
    "\n",
    "            # Update history\n",
    "            for split in [\"train\", \"val\", \"test\"]:\n",
    "                history_loss[split].append(epoch_loss[split])\n",
    "                history_accuracy[split].append(epoch_accuracy[split])\n",
    "                \n",
    "            writer.add_scalar(\"Train Loss\", epoch_loss['train'], epoch)\n",
    "            writer.add_scalar(\"Valid Loss\", epoch_loss['val'], epoch)\n",
    "            writer.add_scalar(\"Test Loss\", epoch_loss['test'], epoch)\n",
    "            writer.add_scalar(\"Train Accuracy\", epoch_accuracy['train'], epoch)\n",
    "            writer.add_scalar(\"Valid Accuracy\", epoch_accuracy['val'], epoch)\n",
    "            writer.add_scalar(\"Test Accuracy\", epoch_accuracy['test'], epoch)\n",
    "            writer.add_scalar(\"ETA\", time.time()-start_time, epoch)\n",
    "            \n",
    "            # Print info\n",
    "            print(f\"Epoch {epoch+1}:\",\n",
    "                  f\"TrL={epoch_loss['train']:.4f},\",\n",
    "                  f\"TrA={epoch_accuracy['train']:.4f},\",\n",
    "                  f\"VL={epoch_loss['val']:.4f},\",\n",
    "                  f\"VA={epoch_accuracy['val']:.4f},\",\n",
    "                  f\"TeL={epoch_loss['test']:.4f},\",\n",
    "                  f\"TeA={epoch_accuracy['test']:.4f},\",\n",
    "                  f\"LR={optimizer.param_groups[0]['lr']:.5f},\"\n",
    "                  f\"s={time.time()-start_time:.4f},\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "    finally:\n",
    "        # Plot loss\n",
    "        plt.title(\"Loss\")\n",
    "        for split in [\"train\", \"val\", \"test\"]:\n",
    "            plt.plot(history_loss[split], label=split)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        # Plot accuracy\n",
    "        plt.title(\"Accuracy\")\n",
    "        for split in [\"train\", \"val\", \"test\"]:\n",
    "            plt.plot(history_accuracy[split], label=split)\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "852f6ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "\n",
    "    if isinstance(m, nn.Conv3d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5d01a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold no---------0----------------------\n"
     ]
    }
   ],
   "source": [
    "experiment_name=\"run1\"\n",
    "generator = torch.Generator()\n",
    "generator.manual_seed(myseed)\n",
    "test_loader = DataLoader(test_data,  batch_size=8, num_workers=0, drop_last=False, shuffle=False, generator=generator)\n",
    "\n",
    "epochs = 200\n",
    "\n",
    "tv_labels = adni_tv['labels'].tolist()\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for fold,(train_idx,val_idx) in enumerate(skf.split(tv_data, tv_labels)):\n",
    "    writer = SummaryWriter(f\"runs/adni2_multi_input/{experiment_name}/{fold}\", filename_suffix=f\"_F{fold}_E{epochs}\")\n",
    "    print('------------fold no---------{}----------------------'.format(fold))   \n",
    "    train_df = adni_tv.iloc[train_idx]\n",
    "    train_set = ImgDataset(adni_df=train_df)\n",
    "\n",
    "    val_df = adni_tv.iloc[val_idx]\n",
    "    val_set = ImgDataset(adni_df=val_df)\n",
    "    \n",
    "    train_loader = DataLoader(train_set, batch_size=8, drop_last=False)\n",
    "    val_loader = DataLoader(val_set, batch_size=8, drop_last=False)\n",
    "    \n",
    "    # Define dictionary of loaders\n",
    "    loaders = {\"train\": train_loader,\n",
    "               \"val\": val_loader,\n",
    "               \"test\": test_loader}\n",
    "\n",
    "    # Model Params\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n",
    "    # Define a loss \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr = 0.01, epochs=epochs, steps_per_epoch=len(train_loader))\n",
    "    \n",
    "    \n",
    "    #model, optimizer = ipex.optimize(model, optimizer=optimizer,dtype=torch.double)\n",
    "    #model = model.float()\n",
    "    # Train model\n",
    "    train(model, loaders, optimizer, criterion, epochs=epochs, dev=dev)\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "    model.apply(reset_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2373de4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "TensorBoard 2.11.0 at http://aiicxnode2:6002/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Check the tensorboard aftern enabling the port fwd using same port: localhost:6002\n",
    "!tensorboard --logdir runs/adni2_img-only --bind_all --load_fast=false --port=6002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576baca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
